# =============================================================================
# MAIN CONFIGURATION
# =============================================================================
spring.application.name=CourierDataSimulator
server.port=8090

# =============================================================================
# DATABASE CONFIGURATION (MySQL for CDC)
# =============================================================================
spring.datasource.url=jdbc:mysql://localhost:3306/package_db?useSSL=false&serverTimezone=UTC&allowPublicKeyRetrieval=true
spring.datasource.username=dbuser
spring.datasource.password=dbpass
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver

# Hikari Connection Pool
spring.datasource.hikari.maximum-pool-size=10
spring.datasource.hikari.minimum-idle=5

# JPA/Hibernate Configuration
spring.jpa.database-platform=org.hibernate.dialect.MySQLDialect
spring.jpa.hibernate.ddl-auto=none
spring.jpa.show-sql=false
spring.jpa.properties.hibernate.format_sql=true

# Disable automatic data.sql execution (we have docker init scripts)
spring.sql.init.mode=never

# =============================================================================
# KAFKA CONFIGURATION
# =============================================================================
spring.kafka.bootstrap-servers=localhost:9092

# Producer Configuration (for REST endpoints)
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer
spring.kafka.producer.acks=all
spring.kafka.producer.retries=3
spring.kafka.producer.properties.enable.idempotence=true
spring.kafka.producer.properties.spring.json.add.type.headers=true

# Consumer Configuration
spring.kafka.consumer.group-id=package-consumer-group
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.properties.spring.json.trusted.packages=*
spring.kafka.consumer.properties.spring.json.value.default.type=com.ekasikci.courierdatasimulator.kafka.dto.MappedPackage
spring.kafka.consumer.properties.spring.json.use.type.headers=true


# Kafka Streams Configuration
spring.kafka.streams.application-id=package-stream-processor
spring.kafka.streams.bootstrap-servers=localhost:9092
spring.kafka.streams.properties.default.key.serde=org.apache.kafka.common.serialization.Serdes$StringSerde
spring.kafka.streams.properties.default.value.serde=org.apache.kafka.common.serialization.Serdes$StringSerde
spring.kafka.streams.properties.commit.interval.ms=100
spring.kafka.streams.properties.cache.max.bytes.buffering=0
spring.kafka.streams.properties.producer.properties.spring.json.add.type.headers=true
spring.kafka.streams.state-dir=/tmp/kafka-streams
# Wait indefinitely for the input topic to be created by Debezium
spring.kafka.streams.properties.metadata.max.age.ms=5000 
spring.kafka.streams.properties.retry.backoff.ms=1000



# =============================================================================
# CUSTOM APPLICATION PROPERTIES
# =============================================================================

# Kafka Topics
app.kafka.topics.cdc-packages=dbserver.package_db.packages
app.kafka.topics.mapped-packages=cdc-mapped-packages
app.kafka.topics.packages=packages

# Legacy partitioning config (keep for REST endpoints)
kafka.topic.packages=mapped-packages
kafka.topic.partitions=3
kafka.topic.replication-factor=1
kafka.partitioning.strategy=BY_ID

# Data Generation Configuration
data.generation.enabled=true
data.generation.pattern=CONSTANT
data.generation.base-rate=10
data.generation.duplicate-rate=0.05
data.generation.error-rate=0.02
data.generation.delay-probability=0.10
data.generation.max-delay-seconds=5
data.generation.cancellation-rate=0.15
data.generation.completion-rate=0.80

# Ingestion Strategy Configuration
ingestion.enabled=true
ingestion.strategy=MICROBATCH
ingestion.batch.interval-minutes=5
ingestion.batch.max-size=1000
ingestion.microbatch.interval-seconds=1
ingestion.microbatch.max-size=100
ingestion.streaming.enabled=true
ingestion.streaming.async=true

# Data Generator Config
app.data-generator.batch-size=100
app.data-generator.delay-ms=10000

# Performance Monitoring
metrics.enabled=true
metrics.log-interval-seconds=30
performance.track-latency=true
performance.track-throughput=true
performance.track-resource-usage=true

# =============================================================================
# LOGGING
# =============================================================================
logging.level.root=INFO
logging.level.com.ekasikci.courierdatasimulator=DEBUG
logging.level.org.springframework.kafka=WARN
logging.level.org.apache.kafka=WARN
logging.level.org.apache.kafka.streams=INFO
logging.level.org.hibernate.SQL=INFO

# =============================================================================
# ACTUATOR
# =============================================================================
management.endpoints.web.exposure.include=health,metrics,info
management.endpoint.health.show-details=always